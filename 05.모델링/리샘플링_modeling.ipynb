{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "\n",
    "from scipy.stats import mstats\n",
    "import statsmodels.api as sm\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression, Lasso, LassoCV\n",
    "from sklearn.metrics import recall_score,accuracy_score, mean_squared_error, r2_score, log_loss, precision_score\n",
    "\n",
    "from sklearn.preprocessing import RobustScaler, MinMaxScaler, StandardScaler\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from scipy.stats import ttest_ind\n",
    "\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "\n",
    "plt.rcParams['font.family'] = 'Malgun Gothic'\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import recall_score,accuracy_score, precision_score,roc_auc_score,f1_score,confusion_matrix\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier\n",
    "# from pytorch_tabnet.tab_model import TabNetClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from imblearn.ensemble import RUSBoostClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0.파일 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Symbol</th>\n",
       "      <th>Name</th>\n",
       "      <th>결산월</th>\n",
       "      <th>회계년</th>\n",
       "      <th>주기</th>\n",
       "      <th>분식기업</th>\n",
       "      <th>매출총이익률(%)</th>\n",
       "      <th>영업이익률(%)</th>\n",
       "      <th>당기순이익률(%)</th>\n",
       "      <th>자본금영업이익률(%)</th>\n",
       "      <th>...</th>\n",
       "      <th>현금흐름/총자본(%)</th>\n",
       "      <th>영업현금흐름/투자현금흐름(%)</th>\n",
       "      <th>DSRI</th>\n",
       "      <th>GMI</th>\n",
       "      <th>AQI</th>\n",
       "      <th>DEPI</th>\n",
       "      <th>SGAI</th>\n",
       "      <th>LVGI</th>\n",
       "      <th>TATA</th>\n",
       "      <th>벤포드</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A095570</td>\n",
       "      <td>AJ네트웍스</td>\n",
       "      <td>12</td>\n",
       "      <td>2015</td>\n",
       "      <td>Annual</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.00</td>\n",
       "      <td>7.03</td>\n",
       "      <td>2.75</td>\n",
       "      <td>183.57</td>\n",
       "      <td>...</td>\n",
       "      <td>89.25</td>\n",
       "      <td>1.43</td>\n",
       "      <td>1.03</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.18</td>\n",
       "      <td>1.01</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A095570</td>\n",
       "      <td>AJ네트웍스</td>\n",
       "      <td>12</td>\n",
       "      <td>2016</td>\n",
       "      <td>Annual</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.00</td>\n",
       "      <td>4.93</td>\n",
       "      <td>1.36</td>\n",
       "      <td>132.12</td>\n",
       "      <td>...</td>\n",
       "      <td>80.01</td>\n",
       "      <td>2.19</td>\n",
       "      <td>1.13</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.28</td>\n",
       "      <td>0.17</td>\n",
       "      <td>1.02</td>\n",
       "      <td>1.03</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A095570</td>\n",
       "      <td>AJ네트웍스</td>\n",
       "      <td>12</td>\n",
       "      <td>2017</td>\n",
       "      <td>Annual</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.00</td>\n",
       "      <td>2.66</td>\n",
       "      <td>2.45</td>\n",
       "      <td>47.92</td>\n",
       "      <td>...</td>\n",
       "      <td>83.63</td>\n",
       "      <td>1.66</td>\n",
       "      <td>1.96</td>\n",
       "      <td>1.00</td>\n",
       "      <td>8.47</td>\n",
       "      <td>0.14</td>\n",
       "      <td>1.02</td>\n",
       "      <td>1.02</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A095570</td>\n",
       "      <td>AJ네트웍스</td>\n",
       "      <td>12</td>\n",
       "      <td>2018</td>\n",
       "      <td>Annual</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.00</td>\n",
       "      <td>-2.03</td>\n",
       "      <td>3.56</td>\n",
       "      <td>-45.35</td>\n",
       "      <td>...</td>\n",
       "      <td>68.01</td>\n",
       "      <td>1.87</td>\n",
       "      <td>0.53</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.05</td>\n",
       "      <td>1.05</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A095570</td>\n",
       "      <td>AJ네트웍스</td>\n",
       "      <td>12</td>\n",
       "      <td>2019</td>\n",
       "      <td>Annual</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.00</td>\n",
       "      <td>1.56</td>\n",
       "      <td>4.21</td>\n",
       "      <td>33.42</td>\n",
       "      <td>...</td>\n",
       "      <td>52.35</td>\n",
       "      <td>-0.85</td>\n",
       "      <td>1.36</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.80</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.96</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7018</th>\n",
       "      <td>A003280</td>\n",
       "      <td>흥아해운</td>\n",
       "      <td>12</td>\n",
       "      <td>2018</td>\n",
       "      <td>Annual</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.36</td>\n",
       "      <td>-11.11</td>\n",
       "      <td>-85.84</td>\n",
       "      <td>-14.77</td>\n",
       "      <td>...</td>\n",
       "      <td>-59.50</td>\n",
       "      <td>-0.40</td>\n",
       "      <td>8.61</td>\n",
       "      <td>0.39</td>\n",
       "      <td>1.12</td>\n",
       "      <td>0.00</td>\n",
       "      <td>4.51</td>\n",
       "      <td>1.08</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7019</th>\n",
       "      <td>A003280</td>\n",
       "      <td>흥아해운</td>\n",
       "      <td>12</td>\n",
       "      <td>2019</td>\n",
       "      <td>Annual</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.54</td>\n",
       "      <td>-12.10</td>\n",
       "      <td>-50.27</td>\n",
       "      <td>-17.19</td>\n",
       "      <td>...</td>\n",
       "      <td>-53.48</td>\n",
       "      <td>-0.10</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.07</td>\n",
       "      <td>1.02</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7020</th>\n",
       "      <td>A003280</td>\n",
       "      <td>흥아해운</td>\n",
       "      <td>12</td>\n",
       "      <td>2020</td>\n",
       "      <td>Annual</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.26</td>\n",
       "      <td>-6.52</td>\n",
       "      <td>-57.20</td>\n",
       "      <td>-10.13</td>\n",
       "      <td>...</td>\n",
       "      <td>-1586.70</td>\n",
       "      <td>-0.08</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.84</td>\n",
       "      <td>1.18</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7021</th>\n",
       "      <td>A003280</td>\n",
       "      <td>흥아해운</td>\n",
       "      <td>12</td>\n",
       "      <td>2021</td>\n",
       "      <td>Annual</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.94</td>\n",
       "      <td>-2.29</td>\n",
       "      <td>20.11</td>\n",
       "      <td>-2.10</td>\n",
       "      <td>...</td>\n",
       "      <td>73.87</td>\n",
       "      <td>-0.20</td>\n",
       "      <td>2.72</td>\n",
       "      <td>1.19</td>\n",
       "      <td>1.21</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7022</th>\n",
       "      <td>A003280</td>\n",
       "      <td>흥아해운</td>\n",
       "      <td>12</td>\n",
       "      <td>2022</td>\n",
       "      <td>Annual</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25.28</td>\n",
       "      <td>16.69</td>\n",
       "      <td>13.39</td>\n",
       "      <td>24.69</td>\n",
       "      <td>...</td>\n",
       "      <td>32.21</td>\n",
       "      <td>-14.44</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.98</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7023 rows × 46 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Symbol    Name  결산월   회계년      주기  분식기업  매출총이익률(%)  영업이익률(%)  \\\n",
       "0     A095570  AJ네트웍스   12  2015  Annual   0.0     100.00      7.03   \n",
       "1     A095570  AJ네트웍스   12  2016  Annual   0.0     100.00      4.93   \n",
       "2     A095570  AJ네트웍스   12  2017  Annual   0.0     100.00      2.66   \n",
       "3     A095570  AJ네트웍스   12  2018  Annual   0.0     100.00     -2.03   \n",
       "4     A095570  AJ네트웍스   12  2019  Annual   0.0     100.00      1.56   \n",
       "...       ...     ...  ...   ...     ...   ...        ...       ...   \n",
       "7018  A003280    흥아해운   12  2018  Annual   0.0       5.36    -11.11   \n",
       "7019  A003280    흥아해운   12  2019  Annual   0.0       5.54    -12.10   \n",
       "7020  A003280    흥아해운   12  2020  Annual   0.0       8.26     -6.52   \n",
       "7021  A003280    흥아해운   12  2021  Annual   0.0       6.94     -2.29   \n",
       "7022  A003280    흥아해운   12  2022  Annual   0.0      25.28     16.69   \n",
       "\n",
       "      당기순이익률(%)  자본금영업이익률(%)  ...  현금흐름/총자본(%)  영업현금흐름/투자현금흐름(%)  DSRI   GMI  \\\n",
       "0          2.75       183.57  ...        89.25              1.43  1.03  1.00   \n",
       "1          1.36       132.12  ...        80.01              2.19  1.13  1.00   \n",
       "2          2.45        47.92  ...        83.63              1.66  1.96  1.00   \n",
       "3          3.56       -45.35  ...        68.01              1.87  0.53  1.00   \n",
       "4          4.21        33.42  ...        52.35             -0.85  1.36  1.00   \n",
       "...         ...          ...  ...          ...               ...   ...   ...   \n",
       "7018     -85.84       -14.77  ...       -59.50             -0.40  8.61  0.39   \n",
       "7019     -50.27       -17.19  ...       -53.48             -0.10  0.07  0.97   \n",
       "7020     -57.20       -10.13  ...     -1586.70             -0.08  0.69  0.67   \n",
       "7021      20.11        -2.10  ...        73.87             -0.20  2.72  1.19   \n",
       "7022      13.39        24.69  ...        32.21            -14.44  0.97  0.27   \n",
       "\n",
       "       AQI  DEPI  SGAI  LVGI  TATA  벤포드  \n",
       "0     0.81  0.18  1.01  0.96  0.10    0  \n",
       "1     1.28  0.17  1.02  1.03  0.12    0  \n",
       "2     8.47  0.14  1.02  1.02  0.07    0  \n",
       "3     0.44  0.05  1.05  1.00  0.02    0  \n",
       "4     1.80  0.07  0.96  1.00  0.03    0  \n",
       "...    ...   ...   ...   ...   ...  ...  \n",
       "7018  1.12  0.00  4.51  1.08  0.03    0  \n",
       "7019  0.90  0.00  1.07  1.02 -0.00    0  \n",
       "7020  0.73  0.00  0.84  1.18 -0.01    0  \n",
       "7021  1.21  0.01  0.62  0.53  0.00    0  \n",
       "7022  0.72  0.01  0.93  0.98 -0.01    0  \n",
       "\n",
       "[7023 rows x 46 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../data/dataset/코스피_전처리완.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[df.columns[6:]]\n",
    "y = df['분식기업']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.데이터 split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test = train_test_split(X, y, test_size=0.3, stratify=y, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of feature: 40\n",
      "number of data: 4916\n"
     ]
    }
   ],
   "source": [
    "n, d = X_train.shape\n",
    "print(\"number of feature:\", d)  # 변수 개수\n",
    "print(\"number of data:\", n)     # 데이터 개수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>매출총이익률(%)</th>\n",
       "      <th>영업이익률(%)</th>\n",
       "      <th>당기순이익률(%)</th>\n",
       "      <th>자본금영업이익률(%)</th>\n",
       "      <th>영업수익/영업비용(%)</th>\n",
       "      <th>ROE(세전계속사업이익)(%)</th>\n",
       "      <th>자본금세전계속사업이익률(%)</th>\n",
       "      <th>자본금지배주주순이익률(%)</th>\n",
       "      <th>매출액증가율(전년동기)(%)</th>\n",
       "      <th>영업이익증가율(전년동기)(%)</th>\n",
       "      <th>...</th>\n",
       "      <th>현금흐름/총자본(%)</th>\n",
       "      <th>영업현금흐름/투자현금흐름(%)</th>\n",
       "      <th>DSRI</th>\n",
       "      <th>GMI</th>\n",
       "      <th>AQI</th>\n",
       "      <th>DEPI</th>\n",
       "      <th>SGAI</th>\n",
       "      <th>LVGI</th>\n",
       "      <th>TATA</th>\n",
       "      <th>벤포드</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>4916.000000</td>\n",
       "      <td>4916.000000</td>\n",
       "      <td>4916.000000</td>\n",
       "      <td>4916.000000</td>\n",
       "      <td>4916.000000</td>\n",
       "      <td>4916.000000</td>\n",
       "      <td>4916.00000</td>\n",
       "      <td>4916.000000</td>\n",
       "      <td>4916.000000</td>\n",
       "      <td>4916.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>4916.000000</td>\n",
       "      <td>4916.000000</td>\n",
       "      <td>4916.000000</td>\n",
       "      <td>4916.000000</td>\n",
       "      <td>4916.000000</td>\n",
       "      <td>4916.000000</td>\n",
       "      <td>4916.000000</td>\n",
       "      <td>4916.000000</td>\n",
       "      <td>4916.000000</td>\n",
       "      <td>4916.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>22.034933</td>\n",
       "      <td>3.544138</td>\n",
       "      <td>1.702067</td>\n",
       "      <td>301.462667</td>\n",
       "      <td>104.943151</td>\n",
       "      <td>3.329184</td>\n",
       "      <td>314.71438</td>\n",
       "      <td>225.056932</td>\n",
       "      <td>18.775210</td>\n",
       "      <td>0.168910</td>\n",
       "      <td>...</td>\n",
       "      <td>8.600004</td>\n",
       "      <td>-0.944172</td>\n",
       "      <td>1.085161</td>\n",
       "      <td>1.074941</td>\n",
       "      <td>1.155167</td>\n",
       "      <td>0.037510</td>\n",
       "      <td>1.029087</td>\n",
       "      <td>1.018318</td>\n",
       "      <td>-0.010492</td>\n",
       "      <td>0.097030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>20.453247</td>\n",
       "      <td>11.916821</td>\n",
       "      <td>36.035633</td>\n",
       "      <td>1359.432268</td>\n",
       "      <td>12.433844</td>\n",
       "      <td>47.948805</td>\n",
       "      <td>1614.55253</td>\n",
       "      <td>1716.880618</td>\n",
       "      <td>584.671105</td>\n",
       "      <td>2984.140321</td>\n",
       "      <td>...</td>\n",
       "      <td>37.323175</td>\n",
       "      <td>28.549077</td>\n",
       "      <td>1.676511</td>\n",
       "      <td>5.074056</td>\n",
       "      <td>1.424999</td>\n",
       "      <td>0.089438</td>\n",
       "      <td>0.470588</td>\n",
       "      <td>0.341328</td>\n",
       "      <td>0.062782</td>\n",
       "      <td>0.296029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-139.970000</td>\n",
       "      <td>-171.390000</td>\n",
       "      <td>-1148.680000</td>\n",
       "      <td>-2111.060000</td>\n",
       "      <td>36.850000</td>\n",
       "      <td>-2309.940000</td>\n",
       "      <td>-3145.61000</td>\n",
       "      <td>-3248.630000</td>\n",
       "      <td>-98.010000</td>\n",
       "      <td>-137079.350000</td>\n",
       "      <td>...</td>\n",
       "      <td>-1586.700000</td>\n",
       "      <td>-412.220000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-150.020000</td>\n",
       "      <td>0.090000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-22.520000</td>\n",
       "      <td>0.110000</td>\n",
       "      <td>-0.770000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>10.230000</td>\n",
       "      <td>1.460000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>15.220000</td>\n",
       "      <td>101.487500</td>\n",
       "      <td>1.137500</td>\n",
       "      <td>6.11500</td>\n",
       "      <td>2.062500</td>\n",
       "      <td>-4.412500</td>\n",
       "      <td>-44.932500</td>\n",
       "      <td>...</td>\n",
       "      <td>5.060000</td>\n",
       "      <td>-1.780000</td>\n",
       "      <td>0.870000</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.930000</td>\n",
       "      <td>0.930000</td>\n",
       "      <td>-0.040000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>16.260000</td>\n",
       "      <td>4.120000</td>\n",
       "      <td>2.995000</td>\n",
       "      <td>82.940000</td>\n",
       "      <td>104.300000</td>\n",
       "      <td>6.900000</td>\n",
       "      <td>75.58500</td>\n",
       "      <td>52.900000</td>\n",
       "      <td>3.670000</td>\n",
       "      <td>-2.885000</td>\n",
       "      <td>...</td>\n",
       "      <td>10.550000</td>\n",
       "      <td>-0.860000</td>\n",
       "      <td>0.980000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>1.010000</td>\n",
       "      <td>0.990000</td>\n",
       "      <td>-0.010000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>27.190000</td>\n",
       "      <td>7.490000</td>\n",
       "      <td>6.470000</td>\n",
       "      <td>252.600000</td>\n",
       "      <td>108.100000</td>\n",
       "      <td>13.012500</td>\n",
       "      <td>263.24500</td>\n",
       "      <td>186.040000</td>\n",
       "      <td>13.712500</td>\n",
       "      <td>37.650000</td>\n",
       "      <td>...</td>\n",
       "      <td>17.012500</td>\n",
       "      <td>-0.080000</td>\n",
       "      <td>1.100000</td>\n",
       "      <td>1.100000</td>\n",
       "      <td>1.130000</td>\n",
       "      <td>0.030000</td>\n",
       "      <td>1.090000</td>\n",
       "      <td>1.050000</td>\n",
       "      <td>0.020000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>100.000000</td>\n",
       "      <td>81.180000</td>\n",
       "      <td>1079.840000</td>\n",
       "      <td>50556.070000</td>\n",
       "      <td>531.400000</td>\n",
       "      <td>498.660000</td>\n",
       "      <td>49541.57000</td>\n",
       "      <td>100051.640000</td>\n",
       "      <td>40693.190000</td>\n",
       "      <td>116066.340000</td>\n",
       "      <td>...</td>\n",
       "      <td>228.330000</td>\n",
       "      <td>1256.760000</td>\n",
       "      <td>83.470000</td>\n",
       "      <td>185.240000</td>\n",
       "      <td>46.180000</td>\n",
       "      <td>0.980000</td>\n",
       "      <td>14.140000</td>\n",
       "      <td>10.180000</td>\n",
       "      <td>0.460000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 40 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         매출총이익률(%)     영업이익률(%)    당기순이익률(%)   자본금영업이익률(%)  영업수익/영업비용(%)  \\\n",
       "count  4916.000000  4916.000000  4916.000000   4916.000000   4916.000000   \n",
       "mean     22.034933     3.544138     1.702067    301.462667    104.943151   \n",
       "std      20.453247    11.916821    36.035633   1359.432268     12.433844   \n",
       "min    -139.970000  -171.390000 -1148.680000  -2111.060000     36.850000   \n",
       "25%      10.230000     1.460000     0.200000     15.220000    101.487500   \n",
       "50%      16.260000     4.120000     2.995000     82.940000    104.300000   \n",
       "75%      27.190000     7.490000     6.470000    252.600000    108.100000   \n",
       "max     100.000000    81.180000  1079.840000  50556.070000    531.400000   \n",
       "\n",
       "       ROE(세전계속사업이익)(%)  자본금세전계속사업이익률(%)  자본금지배주주순이익률(%)  매출액증가율(전년동기)(%)  \\\n",
       "count       4916.000000       4916.00000     4916.000000      4916.000000   \n",
       "mean           3.329184        314.71438      225.056932        18.775210   \n",
       "std           47.948805       1614.55253     1716.880618       584.671105   \n",
       "min        -2309.940000      -3145.61000    -3248.630000       -98.010000   \n",
       "25%            1.137500          6.11500        2.062500        -4.412500   \n",
       "50%            6.900000         75.58500       52.900000         3.670000   \n",
       "75%           13.012500        263.24500      186.040000        13.712500   \n",
       "max          498.660000      49541.57000   100051.640000     40693.190000   \n",
       "\n",
       "       영업이익증가율(전년동기)(%)  ...  현금흐름/총자본(%)  영업현금흐름/투자현금흐름(%)         DSRI  \\\n",
       "count       4916.000000  ...  4916.000000       4916.000000  4916.000000   \n",
       "mean           0.168910  ...     8.600004         -0.944172     1.085161   \n",
       "std         2984.140321  ...    37.323175         28.549077     1.676511   \n",
       "min      -137079.350000  ... -1586.700000       -412.220000     0.000000   \n",
       "25%          -44.932500  ...     5.060000         -1.780000     0.870000   \n",
       "50%           -2.885000  ...    10.550000         -0.860000     0.980000   \n",
       "75%           37.650000  ...    17.012500         -0.080000     1.100000   \n",
       "max       116066.340000  ...   228.330000       1256.760000    83.470000   \n",
       "\n",
       "               GMI          AQI         DEPI         SGAI         LVGI  \\\n",
       "count  4916.000000  4916.000000  4916.000000  4916.000000  4916.000000   \n",
       "mean      1.074941     1.155167     0.037510     1.029087     1.018318   \n",
       "std       5.074056     1.424999     0.089438     0.470588     0.341328   \n",
       "min    -150.020000     0.090000     0.000000   -22.520000     0.110000   \n",
       "25%       0.900000     0.900000     0.000000     0.930000     0.930000   \n",
       "50%       1.000000     1.000000     0.010000     1.010000     0.990000   \n",
       "75%       1.100000     1.130000     0.030000     1.090000     1.050000   \n",
       "max     185.240000    46.180000     0.980000    14.140000    10.180000   \n",
       "\n",
       "              TATA          벤포드  \n",
       "count  4916.000000  4916.000000  \n",
       "mean     -0.010492     0.097030  \n",
       "std       0.062782     0.296029  \n",
       "min      -0.770000     0.000000  \n",
       "25%      -0.040000     0.000000  \n",
       "50%      -0.010000     0.000000  \n",
       "75%       0.020000     0.000000  \n",
       "max       0.460000     1.000000  \n",
       "\n",
       "[8 rows x 40 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "분식기업\n",
      "0.0    4817\n",
      "1.0      99\n",
      "Name: count, dtype: int64\n",
      "분식기업\n",
      "0.0    2064\n",
      "1.0      43\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(y_train.value_counts())\n",
    "print(y_test.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. train set 리샘플링"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "from matplotlib import pyplot\n",
    "def count_and_plot(y):\n",
    "    counter = Counter(y)\n",
    "    for k, v in counter.items():\n",
    "        print('Class=%d, n=%d (%.3f%%)' %(k,v,v /len(y) *100))\n",
    "    pyplot.bar(counter.keys(), counter.values())\n",
    "    pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class=0, n=4807 (49.948%)\n",
      "Class=1, n=4817 (50.052%)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from imblearn.combine import SMOTETomek\n",
    "from imblearn.under_sampling import TomekLinks\n",
    "smoteto = SMOTETomek(tomek=TomekLinks(sampling_strategy='majority'))\n",
    "X_train_resampled_t, y_train_resampled_t = smoteto.fit_resample(X_train, y_train)\n",
    "count_and_plot(y_train_resampled_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>매출총이익률(%)</th>\n",
       "      <th>영업이익률(%)</th>\n",
       "      <th>당기순이익률(%)</th>\n",
       "      <th>자본금영업이익률(%)</th>\n",
       "      <th>영업수익/영업비용(%)</th>\n",
       "      <th>ROE(세전계속사업이익)(%)</th>\n",
       "      <th>자본금세전계속사업이익률(%)</th>\n",
       "      <th>자본금지배주주순이익률(%)</th>\n",
       "      <th>매출액증가율(전년동기)(%)</th>\n",
       "      <th>영업이익증가율(전년동기)(%)</th>\n",
       "      <th>...</th>\n",
       "      <th>현금흐름/총자본(%)</th>\n",
       "      <th>영업현금흐름/투자현금흐름(%)</th>\n",
       "      <th>DSRI</th>\n",
       "      <th>GMI</th>\n",
       "      <th>AQI</th>\n",
       "      <th>DEPI</th>\n",
       "      <th>SGAI</th>\n",
       "      <th>LVGI</th>\n",
       "      <th>TATA</th>\n",
       "      <th>벤포드</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20.880000</td>\n",
       "      <td>4.960000</td>\n",
       "      <td>1.180000</td>\n",
       "      <td>802.860000</td>\n",
       "      <td>105.210000</td>\n",
       "      <td>4.980000</td>\n",
       "      <td>336.400000</td>\n",
       "      <td>127.310000</td>\n",
       "      <td>7.870000</td>\n",
       "      <td>67.860000</td>\n",
       "      <td>...</td>\n",
       "      <td>11.050000</td>\n",
       "      <td>-1.280000</td>\n",
       "      <td>1.050000</td>\n",
       "      <td>0.920000</td>\n",
       "      <td>0.970000</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.010000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9.460000</td>\n",
       "      <td>-16.450000</td>\n",
       "      <td>-37.050000</td>\n",
       "      <td>-117.640000</td>\n",
       "      <td>85.880000</td>\n",
       "      <td>-22.420000</td>\n",
       "      <td>-160.930000</td>\n",
       "      <td>-260.950000</td>\n",
       "      <td>-1.470000</td>\n",
       "      <td>-541.680000</td>\n",
       "      <td>...</td>\n",
       "      <td>-35.020000</td>\n",
       "      <td>-0.680000</td>\n",
       "      <td>0.790000</td>\n",
       "      <td>1.930000</td>\n",
       "      <td>1.070000</td>\n",
       "      <td>0.020000</td>\n",
       "      <td>1.770000</td>\n",
       "      <td>1.130000</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.960000</td>\n",
       "      <td>-8.570000</td>\n",
       "      <td>-10.000000</td>\n",
       "      <td>-610.380000</td>\n",
       "      <td>92.100000</td>\n",
       "      <td>-39.870000</td>\n",
       "      <td>-832.900000</td>\n",
       "      <td>-713.660000</td>\n",
       "      <td>38.430000</td>\n",
       "      <td>33.110000</td>\n",
       "      <td>...</td>\n",
       "      <td>-17.730000</td>\n",
       "      <td>0.180000</td>\n",
       "      <td>0.870000</td>\n",
       "      <td>0.630000</td>\n",
       "      <td>1.120000</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>1.120000</td>\n",
       "      <td>1.090000</td>\n",
       "      <td>-0.070000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6.010000</td>\n",
       "      <td>1.480000</td>\n",
       "      <td>0.270000</td>\n",
       "      <td>211.050000</td>\n",
       "      <td>101.500000</td>\n",
       "      <td>0.760000</td>\n",
       "      <td>37.970000</td>\n",
       "      <td>73.340000</td>\n",
       "      <td>-1.430000</td>\n",
       "      <td>-60.010000</td>\n",
       "      <td>...</td>\n",
       "      <td>6.670000</td>\n",
       "      <td>-0.390000</td>\n",
       "      <td>1.080000</td>\n",
       "      <td>1.410000</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.940000</td>\n",
       "      <td>1.050000</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>21.190000</td>\n",
       "      <td>6.990000</td>\n",
       "      <td>4.830000</td>\n",
       "      <td>168.290000</td>\n",
       "      <td>107.520000</td>\n",
       "      <td>18.550000</td>\n",
       "      <td>141.050000</td>\n",
       "      <td>116.280000</td>\n",
       "      <td>3.540000</td>\n",
       "      <td>25.720000</td>\n",
       "      <td>...</td>\n",
       "      <td>25.390000</td>\n",
       "      <td>-0.180000</td>\n",
       "      <td>2.120000</td>\n",
       "      <td>1.020000</td>\n",
       "      <td>1.190000</td>\n",
       "      <td>0.030000</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.920000</td>\n",
       "      <td>0.070000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9619</th>\n",
       "      <td>32.091690</td>\n",
       "      <td>4.160583</td>\n",
       "      <td>3.171811</td>\n",
       "      <td>85.142434</td>\n",
       "      <td>104.347847</td>\n",
       "      <td>12.864064</td>\n",
       "      <td>87.264345</td>\n",
       "      <td>63.429537</td>\n",
       "      <td>6.262012</td>\n",
       "      <td>-2.900484</td>\n",
       "      <td>...</td>\n",
       "      <td>11.429517</td>\n",
       "      <td>0.873300</td>\n",
       "      <td>1.005211</td>\n",
       "      <td>0.992052</td>\n",
       "      <td>0.963280</td>\n",
       "      <td>0.377807</td>\n",
       "      <td>1.022193</td>\n",
       "      <td>1.005755</td>\n",
       "      <td>0.020000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9620</th>\n",
       "      <td>6.491216</td>\n",
       "      <td>2.834388</td>\n",
       "      <td>0.586626</td>\n",
       "      <td>90.383974</td>\n",
       "      <td>102.916582</td>\n",
       "      <td>4.839168</td>\n",
       "      <td>33.498988</td>\n",
       "      <td>25.164384</td>\n",
       "      <td>4.397490</td>\n",
       "      <td>-20.520162</td>\n",
       "      <td>...</td>\n",
       "      <td>7.199726</td>\n",
       "      <td>0.759153</td>\n",
       "      <td>0.928016</td>\n",
       "      <td>1.154178</td>\n",
       "      <td>1.093418</td>\n",
       "      <td>0.017806</td>\n",
       "      <td>1.025358</td>\n",
       "      <td>1.035612</td>\n",
       "      <td>0.070000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9621</th>\n",
       "      <td>16.429506</td>\n",
       "      <td>0.632588</td>\n",
       "      <td>-0.663120</td>\n",
       "      <td>13.766786</td>\n",
       "      <td>100.632701</td>\n",
       "      <td>-2.300709</td>\n",
       "      <td>-24.491464</td>\n",
       "      <td>-14.655188</td>\n",
       "      <td>2.953946</td>\n",
       "      <td>-72.797828</td>\n",
       "      <td>...</td>\n",
       "      <td>5.588940</td>\n",
       "      <td>0.343371</td>\n",
       "      <td>1.118987</td>\n",
       "      <td>1.155514</td>\n",
       "      <td>0.999887</td>\n",
       "      <td>0.020000</td>\n",
       "      <td>0.948987</td>\n",
       "      <td>1.108875</td>\n",
       "      <td>0.019212</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9622</th>\n",
       "      <td>6.651875</td>\n",
       "      <td>2.843421</td>\n",
       "      <td>0.718317</td>\n",
       "      <td>87.608968</td>\n",
       "      <td>102.924227</td>\n",
       "      <td>5.776361</td>\n",
       "      <td>37.493917</td>\n",
       "      <td>31.353354</td>\n",
       "      <td>8.834827</td>\n",
       "      <td>-25.752901</td>\n",
       "      <td>...</td>\n",
       "      <td>8.683822</td>\n",
       "      <td>0.521879</td>\n",
       "      <td>0.860268</td>\n",
       "      <td>1.215437</td>\n",
       "      <td>1.101342</td>\n",
       "      <td>0.030469</td>\n",
       "      <td>1.009463</td>\n",
       "      <td>1.038389</td>\n",
       "      <td>0.068658</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9623</th>\n",
       "      <td>9.939019</td>\n",
       "      <td>2.889954</td>\n",
       "      <td>-6.598834</td>\n",
       "      <td>74.096738</td>\n",
       "      <td>103.128190</td>\n",
       "      <td>-22.767054</td>\n",
       "      <td>-56.014323</td>\n",
       "      <td>-91.783098</td>\n",
       "      <td>0.471703</td>\n",
       "      <td>-76.562724</td>\n",
       "      <td>...</td>\n",
       "      <td>-16.838128</td>\n",
       "      <td>2.053757</td>\n",
       "      <td>0.845583</td>\n",
       "      <td>1.714739</td>\n",
       "      <td>0.620337</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.790445</td>\n",
       "      <td>1.035414</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9624 rows × 40 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      매출총이익률(%)   영업이익률(%)  당기순이익률(%)  자본금영업이익률(%)  영업수익/영업비용(%)  \\\n",
       "0     20.880000   4.960000   1.180000   802.860000    105.210000   \n",
       "1      9.460000 -16.450000 -37.050000  -117.640000     85.880000   \n",
       "2      4.960000  -8.570000 -10.000000  -610.380000     92.100000   \n",
       "3      6.010000   1.480000   0.270000   211.050000    101.500000   \n",
       "4     21.190000   6.990000   4.830000   168.290000    107.520000   \n",
       "...         ...        ...        ...          ...           ...   \n",
       "9619  32.091690   4.160583   3.171811    85.142434    104.347847   \n",
       "9620   6.491216   2.834388   0.586626    90.383974    102.916582   \n",
       "9621  16.429506   0.632588  -0.663120    13.766786    100.632701   \n",
       "9622   6.651875   2.843421   0.718317    87.608968    102.924227   \n",
       "9623   9.939019   2.889954  -6.598834    74.096738    103.128190   \n",
       "\n",
       "      ROE(세전계속사업이익)(%)  자본금세전계속사업이익률(%)  자본금지배주주순이익률(%)  매출액증가율(전년동기)(%)  \\\n",
       "0             4.980000       336.400000      127.310000         7.870000   \n",
       "1           -22.420000      -160.930000     -260.950000        -1.470000   \n",
       "2           -39.870000      -832.900000     -713.660000        38.430000   \n",
       "3             0.760000        37.970000       73.340000        -1.430000   \n",
       "4            18.550000       141.050000      116.280000         3.540000   \n",
       "...                ...              ...             ...              ...   \n",
       "9619         12.864064        87.264345       63.429537         6.262012   \n",
       "9620          4.839168        33.498988       25.164384         4.397490   \n",
       "9621         -2.300709       -24.491464      -14.655188         2.953946   \n",
       "9622          5.776361        37.493917       31.353354         8.834827   \n",
       "9623        -22.767054       -56.014323      -91.783098         0.471703   \n",
       "\n",
       "      영업이익증가율(전년동기)(%)  ...  현금흐름/총자본(%)  영업현금흐름/투자현금흐름(%)      DSRI  \\\n",
       "0            67.860000  ...    11.050000         -1.280000  1.050000   \n",
       "1          -541.680000  ...   -35.020000         -0.680000  0.790000   \n",
       "2            33.110000  ...   -17.730000          0.180000  0.870000   \n",
       "3           -60.010000  ...     6.670000         -0.390000  1.080000   \n",
       "4            25.720000  ...    25.390000         -0.180000  2.120000   \n",
       "...                ...  ...          ...               ...       ...   \n",
       "9619         -2.900484  ...    11.429517          0.873300  1.005211   \n",
       "9620        -20.520162  ...     7.199726          0.759153  0.928016   \n",
       "9621        -72.797828  ...     5.588940          0.343371  1.118987   \n",
       "9622        -25.752901  ...     8.683822          0.521879  0.860268   \n",
       "9623        -76.562724  ...   -16.838128          2.053757  0.845583   \n",
       "\n",
       "           GMI       AQI      DEPI      SGAI      LVGI      TATA  벤포드  \n",
       "0     0.920000  0.970000  0.010000  1.000000  1.000000 -0.010000    0  \n",
       "1     1.930000  1.070000  0.020000  1.770000  1.130000  0.010000    0  \n",
       "2     0.630000  1.120000  0.010000  1.120000  1.090000 -0.070000    0  \n",
       "3     1.410000  0.900000  0.010000  0.940000  1.050000  0.010000    0  \n",
       "4     1.020000  1.190000  0.030000  0.900000  0.920000  0.070000    0  \n",
       "...        ...       ...       ...       ...       ...       ...  ...  \n",
       "9619  0.992052  0.963280  0.377807  1.022193  1.005755  0.020000    0  \n",
       "9620  1.154178  1.093418  0.017806  1.025358  1.035612  0.070000    0  \n",
       "9621  1.155514  0.999887  0.020000  0.948987  1.108875  0.019212    0  \n",
       "9622  1.215437  1.101342  0.030469  1.009463  1.038389  0.068658    0  \n",
       "9623  1.714739  0.620337  0.010000  0.790445  1.035414  0.000000    0  \n",
       "\n",
       "[9624 rows x 40 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_resampled_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "분식기업\n",
       "1.0    4817\n",
       "0.0    4807\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_resampled_t.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 모델링"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 로지스틱 회귀 분석"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6454674893213099\n",
      "Precision: 0.03562005277044855\n",
      "Recall: 0.627906976744186\n",
      "F1 Score: 0.06741573033707866\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, f1_score, \n",
    "    roc_curve, auc, RocCurveDisplay\n",
    ")\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 로지스틱 회귀 모델 생성과 학습\n",
    "model = LogisticRegression(random_state = 42)\n",
    "model.fit(X_train_resampled_t, y_train_resampled_t)\n",
    "\n",
    "# 테스트 데이터에 대한 예측\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# 다양한 평가 지표 출력\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"F1 Score:\", f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6869285120532004\n",
      "Precision: 0.6712224753227031\n",
      "Recall: 0.7340668465850114\n",
      "F1 Score: 0.7012394645513138\n"
     ]
    }
   ],
   "source": [
    "y_train_pred = model.predict(X_train_resampled_t)\n",
    "accuracy = accuracy_score(y_train_resampled_t, y_train_pred)\n",
    "precision = precision_score(y_train_resampled_t, y_train_pred)\n",
    "recall = recall_score(y_train_resampled_t, y_train_pred)\n",
    "f1 = f1_score(y_train_resampled_t, y_train_pred)\n",
    "\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"F1 Score:\", f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 catboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9629805410536307\n",
      "Precision: 0.26666666666666666\n",
      "Recall: 0.46511627906976744\n",
      "F1 Score: 0.3389830508474576\n"
     ]
    }
   ],
   "source": [
    "from catboost import CatBoostClassifier, Pool\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# CatBoost 모델 생성\n",
    "model = CatBoostClassifier(iterations=100, learning_rate=0.1, loss_function='Logloss', random_state = 42)\n",
    "\n",
    "# 모델 학습\n",
    "model.fit(X_train_resampled_t, y_train_resampled_t, verbose=0)\n",
    "\n",
    "# 테스트 데이터에 대한 예측\n",
    "y_pred2 = model.predict(X_test)\n",
    "\n",
    "# 다양한 평가 지표 출력\n",
    "accuracy = accuracy_score(y_test, y_pred2)\n",
    "precision = precision_score(y_test, y_pred2)\n",
    "recall = recall_score(y_test, y_pred2)\n",
    "f1 = f1_score(y_test, y_pred2)\n",
    "\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"F1 Score:\", f1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3-3. Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9250118652112007\n",
      "Precision: 0.10884353741496598\n",
      "Recall: 0.37209302325581395\n",
      "F1 Score: 0.16842105263157894\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# Decision Tree 모델 생성\n",
    "model = DecisionTreeClassifier(random_state = 42)\n",
    "\n",
    "# 모델 학습\n",
    "model.fit(X_train_resampled_t, y_train_resampled_t)\n",
    "\n",
    "# 테스트 데이터에 대한 예측\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# 다양한 평가 지표 출력\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"F1 Score:\", f1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 나이브베이즈"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.29093497864261986\n",
      "Precision: 0.024262295081967214\n",
      "Recall: 0.8604651162790697\n",
      "F1 Score: 0.04719387755102041\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "\n",
    "# 기본 나이브 베이즈 분류기 생성\n",
    "base_model = GaussianNB()\n",
    "\n",
    "# 배깅 분류기 생성\n",
    "model = BaggingClassifier(base_model, n_estimators=10, random_state=42)\n",
    "\n",
    "# 모델 학습\n",
    "model.fit(X_train_resampled_t, y_train_resampled_t)\n",
    "\n",
    "# 테스트 데이터에 대한 예측\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# 다양한 평가 지표 출력\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"F1 Score:\", f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. 성능 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.DataFrame()\n",
    "test_df = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1333  731]\n",
      " [  16   27]]\n"
     ]
    }
   ],
   "source": [
    "logit = LogisticRegression(random_state = 42)\n",
    "logit.fit(X_train_resampled_t, y_train_resampled_t)\n",
    "y_pred_train = logit.predict(X_train_resampled_t)\n",
    "y_pred_test = logit.predict(X_test)\n",
    "\n",
    "log_train = [accuracy_score(y_train_resampled_t, y_pred_train),precision_score(y_train_resampled_t, y_pred_train),recall_score(y_train_resampled_t, y_pred_train),f1_score(y_train_resampled_t, y_pred_train),roc_auc_score(y_train_resampled_t, y_pred_train)]\n",
    "log_test = [accuracy_score(y_test, y_pred_test),precision_score(y_test, y_pred_test),recall_score(y_test, y_pred_test),f1_score(y_test, y_pred_test),roc_auc_score(y_test, y_pred_test)]\n",
    "\n",
    "train_df['logit_train'] = log_train\n",
    "test_df['logit_test'] = log_test\n",
    "\n",
    "print(confusion_matrix(y_test,y_pred_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2052   12]\n",
      " [  28   15]]\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestClassifier(random_state=42)\n",
    "rf.fit(X_train_resampled_t, y_train_resampled_t)\n",
    "y_pred_train = rf.predict(X_train_resampled_t)\n",
    "y_pred_test = rf.predict(X_test)\n",
    "\n",
    "rf_train = [accuracy_score(y_train_resampled_t, y_pred_train),precision_score(y_train_resampled_t, y_pred_train),recall_score(y_train_resampled_t, y_pred_train),f1_score(y_train_resampled_t, y_pred_train),roc_auc_score(y_train_resampled_t, y_pred_train)]\n",
    "rf_test = [accuracy_score(y_test, y_pred_test),precision_score(y_test, y_pred_test),recall_score(y_test, y_pred_test),f1_score(y_test, y_pred_test),roc_auc_score(y_test, y_pred_test)]\n",
    "\n",
    "train_df['rf_train'] = rf_train\n",
    "test_df['rf_test'] = rf_test\n",
    "\n",
    "\n",
    "print(confusion_matrix(y_test,y_pred_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1717  347]\n",
      " [  20   23]]\n"
     ]
    }
   ],
   "source": [
    "ad_clf = AdaBoostClassifier(random_state = 42)\n",
    "ad_clf.fit(X_train_resampled_t, y_train_resampled_t)\n",
    "y_pred_train = ad_clf.predict(X_train_resampled_t)\n",
    "y_pred_test = ad_clf.predict(X_test)\n",
    "\n",
    "ad_train = [accuracy_score(y_train_resampled_t, y_pred_train),precision_score(y_train_resampled_t, y_pred_train),recall_score(y_train_resampled_t, y_pred_train),f1_score(y_train_resampled_t, y_pred_train),roc_auc_score(y_train_resampled_t, y_pred_train)]\n",
    "ad_test = [accuracy_score(y_test, y_pred_test),precision_score(y_test, y_pred_test),recall_score(y_test, y_pred_test),f1_score(y_test, y_pred_test),roc_auc_score(y_test, y_pred_test)]\n",
    "\n",
    "train_df['ad_train'] = ad_train\n",
    "test_df['ad_test'] = ad_test\n",
    "\n",
    "print(confusion_matrix(y_test,y_pred_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1901  163]\n",
      " [  18   25]]\n"
     ]
    }
   ],
   "source": [
    "gb_clf = GradientBoostingClassifier(random_state = 42)\n",
    "gb_clf.fit(X_train_resampled_t, y_train_resampled_t)\n",
    "y_pred_train = gb_clf.predict(X_train_resampled_t)\n",
    "y_pred_test = gb_clf.predict(X_test)\n",
    "\n",
    "gb_train= [accuracy_score(y_train_resampled_t, y_pred_train),precision_score(y_train_resampled_t, y_pred_train),recall_score(y_train_resampled_t, y_pred_train),f1_score(y_train_resampled_t, y_pred_train),roc_auc_score(y_train_resampled_t, y_pred_train)]\n",
    "gb_test = [accuracy_score(y_test, y_pred_test),precision_score(y_test, y_pred_test),recall_score(y_test, y_pred_test),f1_score(y_test, y_pred_test),roc_auc_score(y_test, y_pred_test)]\n",
    "\n",
    "train_df['gb_train'] = gb_train\n",
    "test_df['gb_test'] = gb_test\n",
    "\n",
    "print(confusion_matrix(y_test,y_pred_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1732  332]\n",
      " [  19   24]]\n"
     ]
    }
   ],
   "source": [
    "rus_clf = RUSBoostClassifier(random_state = 42)\n",
    "rus_clf.fit(X_train_resampled_t, y_train_resampled_t)\n",
    "y_pred_train = rus_clf.predict(X_train_resampled_t)\n",
    "y_pred_test = rus_clf.predict(X_test)\n",
    "\n",
    "rus_train= [accuracy_score(y_train_resampled_t, y_pred_train),precision_score(y_train_resampled_t, y_pred_train),recall_score(y_train_resampled_t, y_pred_train),f1_score(y_train_resampled_t, y_pred_train),roc_auc_score(y_train_resampled_t, y_pred_train)]\n",
    "rus_test = [accuracy_score(y_test, y_pred_test),precision_score(y_test, y_pred_test),recall_score(y_test, y_pred_test),f1_score(y_test, y_pred_test),roc_auc_score(y_test, y_pred_test)]\n",
    "\n",
    "train_df['rus_train'] = rus_train\n",
    "test_df['rus_test'] = rus_test\n",
    "\n",
    "print(confusion_matrix(y_test,y_pred_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2048   16]\n",
      " [  22   21]]\n"
     ]
    }
   ],
   "source": [
    "xgb = XGBClassifier(random_state=42)\n",
    "xgb.fit(X_train_resampled_t, y_train_resampled_t)\n",
    "y_pred_train = xgb.predict(X_train_resampled_t)\n",
    "y_pred_test = xgb.predict(X_test)\n",
    "\n",
    "xgb_train = [accuracy_score(y_train_resampled_t, y_pred_train),precision_score(y_train_resampled_t, y_pred_train),recall_score(y_train_resampled_t, y_pred_train),f1_score(y_train_resampled_t, y_pred_train),roc_auc_score(y_train_resampled_t, y_pred_train)]\n",
    "xgb_test = [accuracy_score(y_test, y_pred_test),precision_score(y_test, y_pred_test),recall_score(y_test, y_pred_test),f1_score(y_test, y_pred_test),roc_auc_score(y_test, y_pred_test)]\n",
    "\n",
    "train_df['xgb_train'] = xgb_train\n",
    "test_df['xgb_test'] = xgb_test\n",
    "\n",
    "\n",
    "print(confusion_matrix(y_test,y_pred_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4817, number of negative: 4807\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005261 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 9947\n",
      "[LightGBM] [Info] Number of data points in the train set: 9624, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500520 -> initscore=0.002078\n",
      "[LightGBM] [Info] Start training from score 0.002078\n",
      "[[2044   20]\n",
      " [  19   24]]\n"
     ]
    }
   ],
   "source": [
    "lgb = LGBMClassifier(random_state=42)\n",
    "lgb.fit(X_train_resampled_t, y_train_resampled_t)\n",
    "y_pred_train = lgb.predict(X_train_resampled_t)\n",
    "y_pred_test = lgb.predict(X_test)\n",
    "\n",
    "lgb_train =[accuracy_score(y_train_resampled_t, y_pred_train),precision_score(y_train_resampled_t, y_pred_train),recall_score(y_train_resampled_t, y_pred_train),f1_score(y_train_resampled_t, y_pred_train),roc_auc_score(y_train_resampled_t, y_pred_train)]\n",
    "lgb_test = [accuracy_score(y_test, y_pred_test),precision_score(y_test, y_pred_test),recall_score(y_test, y_pred_test),f1_score(y_test, y_pred_test),roc_auc_score(y_test, y_pred_test)]\n",
    "\n",
    "train_df['lgb_train'] = lgb_train\n",
    "test_df['lgb_test'] = lgb_test\n",
    "\n",
    "\n",
    "print(confusion_matrix(y_test,y_pred_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2052   12]\n",
      " [  27   16]]\n"
     ]
    }
   ],
   "source": [
    "cat = CatBoostClassifier(random_state=42, verbose=0)\n",
    "cat.fit(X_train_resampled_t, y_train_resampled_t)\n",
    "y_pred_train = cat.predict(X_train_resampled_t)\n",
    "y_pred_test = cat.predict(X_test)\n",
    "\n",
    "cat_train = [accuracy_score(y_train_resampled_t, y_pred_train),precision_score(y_train_resampled_t, y_pred_train),recall_score(y_train_resampled_t, y_pred_train),f1_score(y_train_resampled_t, y_pred_train),roc_auc_score(y_train_resampled_t, y_pred_train)]\n",
    "cat_test = [accuracy_score(y_test, y_pred_test),precision_score(y_test, y_pred_test),recall_score(y_test, y_pred_test),f1_score(y_test, y_pred_test),roc_auc_score(y_test, y_pred_test)]\n",
    "\n",
    "train_df['cat_train'] = cat_train\n",
    "test_df['cat_test'] = cat_test\n",
    "\n",
    "\n",
    "print(confusion_matrix(y_test,y_pred_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 327 1737]\n",
      " [   2   41]]\n"
     ]
    }
   ],
   "source": [
    "svc_clf = SVC(random_state = 42) \n",
    "svc_clf.fit(X_train_resampled_t,y_train_resampled_t)\n",
    "y_pred_train = svc_clf.predict(X_train_resampled_t)\n",
    "y_pred_test = svc_clf.predict(X_test)\n",
    "\n",
    "svc_clf_train =[accuracy_score(y_train_resampled_t, y_pred_train),precision_score(y_train_resampled_t, y_pred_train),recall_score(y_train_resampled_t, y_pred_train),f1_score(y_train_resampled_t, y_pred_train),roc_auc_score(y_train_resampled_t, y_pred_train)]\n",
    "svc_clf_test = [accuracy_score(y_test, y_pred_test),precision_score(y_test, y_pred_test),recall_score(y_test, y_pred_test),f1_score(y_test, y_pred_test),roc_auc_score(y_test, y_pred_test)]\n",
    "\n",
    "train_df['svm_train'] = svc_clf_train\n",
    "test_df['svm_test'] = svc_clf_test\n",
    "\n",
    "\n",
    "print(confusion_matrix(y_test,y_pred_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clf = TabNetClassifier()\n",
    "\n",
    "# # 모델 훈련\n",
    "# clf.fit(\n",
    "#     X_train.values, y_train.values,\n",
    "#     eval_set=[(X_train.values, y_train.values), (X_test.values, y_test.values)],\n",
    "#     eval_name=['train', 'test'],\n",
    "#     eval_metric=['accuracy'],\n",
    "#     max_epochs=10,\n",
    "#     patience=10,\n",
    "#     batch_size=1024, \n",
    "#     virtual_batch_size=128,\n",
    "#     num_workers=0,\n",
    "#     drop_last=False\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_pred_train = clf.predict(X_train.values)\n",
    "# y_pred_test = clf.predict(X_test.values)\n",
    "\n",
    "# tab_train = [accuracy_score(y_train, y_pred_train),precision_score(y_train, y_pred_train),recall_score(y_train, y_pred_train),f1_score(y_train, y_pred_train),roc_auc_score(y_train, y_pred_train)]\n",
    "# tab_test = [accuracy_score(y_test, y_pred_test),precision_score(y_test, y_pred_test),recall_score(y_test, y_pred_test),f1_score(y_test, y_pred_test),roc_auc_score(y_test, y_pred_test)]\n",
    "\n",
    "# df['tabnet_train'] = tab_train\n",
    "# df['tabnet_test'] = tab_test\n",
    "\n",
    "\n",
    "# print(confusion_matrix(y_test,y_pred_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "# import pytorch_tabnet\n",
    "\n",
    "# print(\"PyTorch Version:\", torch.__version__)\n",
    "# print(\"pytorch_tabnet Version:\", pytorch_tabnet.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>logit_train</th>\n",
       "      <th>rf_train</th>\n",
       "      <th>ad_train</th>\n",
       "      <th>gb_train</th>\n",
       "      <th>rus_train</th>\n",
       "      <th>xgb_train</th>\n",
       "      <th>lgb_train</th>\n",
       "      <th>cat_train</th>\n",
       "      <th>svm_train</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.686929</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.898587</td>\n",
       "      <td>0.966750</td>\n",
       "      <td>0.900561</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.561409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.671222</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.871974</td>\n",
       "      <td>0.946929</td>\n",
       "      <td>0.875049</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.534348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>0.734067</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.934607</td>\n",
       "      <td>0.988997</td>\n",
       "      <td>0.934814</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.962425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1-score</th>\n",
       "      <td>0.701239</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.902204</td>\n",
       "      <td>0.967506</td>\n",
       "      <td>0.903945</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.687171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>roc-auc</th>\n",
       "      <td>0.686879</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.898549</td>\n",
       "      <td>0.966727</td>\n",
       "      <td>0.900525</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.560992</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           logit_train  rf_train  ad_train  gb_train  rus_train  xgb_train  \\\n",
       "accuracy      0.686929       1.0  0.898587  0.966750   0.900561        1.0   \n",
       "precision     0.671222       1.0  0.871974  0.946929   0.875049        1.0   \n",
       "recall        0.734067       1.0  0.934607  0.988997   0.934814        1.0   \n",
       "f1-score      0.701239       1.0  0.902204  0.967506   0.903945        1.0   \n",
       "roc-auc       0.686879       1.0  0.898549  0.966727   0.900525        1.0   \n",
       "\n",
       "           lgb_train  cat_train  svm_train  \n",
       "accuracy         1.0        1.0   0.561409  \n",
       "precision        1.0        1.0   0.534348  \n",
       "recall           1.0        1.0   0.962425  \n",
       "f1-score         1.0        1.0   0.687171  \n",
       "roc-auc          1.0        1.0   0.560992  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.index = ['accuracy','precision','recall','f1-score','roc-auc']\n",
    "test_df.index = ['accuracy','precision','recall','f1-score','roc-auc']\n",
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>logit_test</th>\n",
       "      <th>rf_test</th>\n",
       "      <th>ad_test</th>\n",
       "      <th>gb_test</th>\n",
       "      <th>rus_test</th>\n",
       "      <th>xgb_test</th>\n",
       "      <th>lgb_test</th>\n",
       "      <th>cat_test</th>\n",
       "      <th>svm_test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.645467</td>\n",
       "      <td>0.981016</td>\n",
       "      <td>0.825819</td>\n",
       "      <td>0.914096</td>\n",
       "      <td>0.833412</td>\n",
       "      <td>0.981965</td>\n",
       "      <td>0.981490</td>\n",
       "      <td>0.981490</td>\n",
       "      <td>0.174656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.035620</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.062162</td>\n",
       "      <td>0.132979</td>\n",
       "      <td>0.067416</td>\n",
       "      <td>0.567568</td>\n",
       "      <td>0.545455</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.023060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>0.627907</td>\n",
       "      <td>0.348837</td>\n",
       "      <td>0.534884</td>\n",
       "      <td>0.581395</td>\n",
       "      <td>0.558140</td>\n",
       "      <td>0.488372</td>\n",
       "      <td>0.558140</td>\n",
       "      <td>0.372093</td>\n",
       "      <td>0.953488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1-score</th>\n",
       "      <td>0.067416</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.111380</td>\n",
       "      <td>0.216450</td>\n",
       "      <td>0.120301</td>\n",
       "      <td>0.525000</td>\n",
       "      <td>0.551724</td>\n",
       "      <td>0.450704</td>\n",
       "      <td>0.045030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>roc-auc</th>\n",
       "      <td>0.636870</td>\n",
       "      <td>0.671512</td>\n",
       "      <td>0.683382</td>\n",
       "      <td>0.751211</td>\n",
       "      <td>0.698643</td>\n",
       "      <td>0.740310</td>\n",
       "      <td>0.774225</td>\n",
       "      <td>0.683140</td>\n",
       "      <td>0.555959</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           logit_test   rf_test   ad_test   gb_test  rus_test  xgb_test  \\\n",
       "accuracy     0.645467  0.981016  0.825819  0.914096  0.833412  0.981965   \n",
       "precision    0.035620  0.555556  0.062162  0.132979  0.067416  0.567568   \n",
       "recall       0.627907  0.348837  0.534884  0.581395  0.558140  0.488372   \n",
       "f1-score     0.067416  0.428571  0.111380  0.216450  0.120301  0.525000   \n",
       "roc-auc      0.636870  0.671512  0.683382  0.751211  0.698643  0.740310   \n",
       "\n",
       "           lgb_test  cat_test  svm_test  \n",
       "accuracy   0.981490  0.981490  0.174656  \n",
       "precision  0.545455  0.571429  0.023060  \n",
       "recall     0.558140  0.372093  0.953488  \n",
       "f1-score   0.551724  0.450704  0.045030  \n",
       "roc-auc    0.774225  0.683140  0.555959  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
