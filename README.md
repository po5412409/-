"# ubion" 

# 01. 분석에 필요한 데이터로 수집 및 가공
- Feature (42개)
[자료수집처] FnGuide
    - FnGuide에서 제공하지 않은 재무비율 직접 생성 필요
        - 안정성 : 유동비율, 당좌비율
        - 활동성 : 매출채권회전율, 재고자산회전율, 고정자산회전율
        - 현금흐름 : 영업현금흐름 / 투자현금흐름
        - Benish_M-score : DSRI, GMI, AQI, SGI, DEPI, SGAI, LVGI, TATA
        - Benford : 해당유무
    - 최종 Feature (40개)
        - 수익성 (8)
        - 성장성 (5)
        - 안정성 (8)
        - 활동성 (7)
        - 현금흐름 (4)
        - Beneish M-Score (7)
        - Benford (1)


- Label
[자료수집처] 금융위원회
    - 금융위원회에서 '사업보고서 및 감사보고서 등에 대한 조사 . 감리결과 조치를 받은 기업' 에서 감리결과 조치를 받은 기업
    - 현금흐름 상 이상이 포착된 기업(?)
    총 데이터 205개 중 전체 코스피 데이터셋에서 해당하지 않는 회계년도와 현대약품 제외
    최종 코스피 분식(1)기업 데이터 194개
    - 전처리 이후
    코스피 분식(1)기업 데이터 142개 // 일반(0)기업 데이터 6887개

# 02. 데이터 전처리
전처리 이전 데이터셋 (13356 / 1100)
## 1. 1차 전처리
1. 2011년 데이터 제거 (12243 / 1100)
2. 결산월 12월 이외의 데이터 제거 (12150 / 1099)
3. 상장 이전 회계년도 데이터 제거 (7751 / 778)
4. 금융업 제거 (WICS 기준 적용) (7313 / 732)
5. 한글데이터 처리 (7313 / 732)
    - ROE(세전계속사업이익)(%), 총자본증가율(전년동기)(%), 영업이익증가율(전년동기)(%), 당기순이익증가율(전년동기)(%), 부채비율(%), 총자본회전율(회), 현금흐름/총자본(%)
    - 연결재무제표 계정 값을 통해 직접 계산으로 문자 데이터 대체
6. 수치형 데이터 데이터 타입 숫자형으로 통일 (7313 / 732)

## 2. 2차 전처리
1. 상장연도 = 회계년도 데이터 제거 (7268 / 731)
2. 현금흐름/총차입부채(%), SGI 컬럼 제거 (7268 / 731)
3. 대체 불가로 삭제 처리 (7265 / 731)
4. 연결재무제표 계산 이후 결측치 개별재무제표로 직접 계산 (7265 / 731)
5. 개별재무제표로 계산 이후에도 처리 불가 데이터 제거 (7045 / 729)
6. 무한대 값 처리 (7029 / 729)

## 3. 이상치 확인
1. 컬럼별 Max, Min 값 3개씩 Dart에 공시된 값과 비교 결과, 실제 값과 일치
    => 오류값이라고 아닌 보존해야할 특이값으로 판단, 최대한 특성을 보존하고자 함
2. 상하위 1%씩 총 2% 윈저라이징 실시 예정

### 이상치 처리에 관하여
로지스틱 리그레션을 통해 스코어를 산출하기 위해서 선형회귀가 필수적인 연구이다.
그러기 위해서 변수 선정 이전에 다중공선성과 이상치 처리를 통해 선형회귀의 신뢰성을 높이려고 한다.

전체 변수의 EDA 및 시각화 결과 모두 정규성을 띄지 않음을 알 수 있다.
그러므로 정상분포에서 이상치를 탐색하는 IQR, Z-Score 방법은 신뢰할 수 없다고 판단하여
중앙값을 활용한 MAD(Median Absoulte Deviation)를 활용하기로 결정하였다.

이상치 처리.ipynb : 변수별 이상치 처리 내용 포함

## 4. 다중공선성 처리
최종 변수 선정을 위한 라쏘, 전진선택 등 선형회귀 기반의 방법 적용하기 이전에 변수 간의 다중공선성 제거



# 03. 데이터 EDA
## 기초EDA
    - 기초통계(describe)
    - Boxplot
    - Violinplot
    - 상관관계


# 04. 변수 선정
## 1차 선택
1. Filter Method : 변수의 통계적 유의성 확인
    - 독립표본 T-test
2. Wrapper Method : 2가지 방법에서 공통으로 추출된 변수만 선택
    - 전진선택법
    - 후진제거법
3. Embedded Method : 3가지 방법 중 2번 이상 공통으로 추출된 변수만 선택
    - Ridge
    - Lasso
    - feature_importances_

## 2차 선택
Filter, Wrapper, Embedded Method 3가지에서 공통으로 겹치는 변수만 최종 변수로 선정

# 05. 모델링
## 사용 알고리즘
- Logistic Regreesion
- Naive Baise
- Decision Tree
- SVM
* 앙상블
    - Random Forest
    - AdaBoost
    - Gradient Boosting
    - RusBoost
    - XGBoost
    - LightGBM
    - CatBoost

### 1. raw_data에 머신러닝 기법 적용
일반 머신러닝 알고리즘의 경우 이상치, 스케일링, feature_selection에 민감하지 않으므로 원본데이터에 대한 모델 성능 확인



### 2. 이상치 처리 이후 머신러닝 기법 적용


### 3. 스케일링 처리 이후 머신러닝 기법 적용

### 4. 리샘플링 처리 이후 머신러닝 기법 적용
- 데이터 불균형 및 1class(분식기업)의 데이터 크기가 매우 작으므로 오버샘플링에 대해서만 고려














'더이상의 전처리는 없다' -> read_csv(./값채우기/) => to_csv(./정제 데이터/코스피.csv)
희선: 1차 전처리 이후 데이터/코스피/자본총계_코스피.csv = (연결재무제표 기준)


review
- 전처리 2-2. 'SGI'와 '매출액증가율(전년동기)(%)'
    - 이름만 다른 같은 의미의 중복 컬럼
    - 'SGI' 삭제 처리

- '당기순이익률(%)', '매출총이익률(%)', '영업이익률(%)', '*판관비율(%)', '현금흐름/영업수익(%)'
    - 대덕 2019 매출액이 0인 문제로 결측치. 해당 기업 데이터에서 해당년도만 빼도 되는건가?
    - 일단 '현금흐름/영업수익(%)'에서 현금흐름 계정값이 없음
    - 삭제 처리

- '매출액증가율(전년동기)(%)', 'GMI'
    - 대덕 2020, 화승엔터프라이즈 2016
    - 전해년도 매출액이 0에서 당해년도 매출액 상승으로 결측치
    - 삭제 처리
    - 개별로 처리했어야 했나

- 이상치 처리
    - 데이터 보존을 위해서 상하위 1%씩 총 2%인데 이것도 많은듯함
    - 데이터 특성을 보존하려고 했으면 아예 처리x -> 모델링 실시 후에 이상치 처리 했었어야 할 것 같음
    - 0기업과 1기업으로 구분해서 boxplot, violinplot 찍어서 본 뒤에 이상치가 많은 쪽만 윈저라이징 했어야 했을 듯

- 이상치 처리 이후 과정
    1. 산식을 만들기 위해 로지스틱 리그레션이 중요했는데 그에 대한 놓친점이 있었던 것 같다.
        1. 선형 회귀이기 때문에 이상치에 민감한 모델이었는데, 이상치를 실제 이상치라는 이유로 1% 줄인 것이 너무 적게 줄인 것 아닌가
        2. 정규성을 만족하지 않는 상태에서 T-test를 진행했기 때문에 결과에 대한 신뢰성이 낮다.
        3. 3가지 방법(T-test, wrapper, embedded)을 통한 교집합으로 변수를 선정하는 것은 좋았는데, 그 과정에서 다중공선성을 선처리로 진행했어야 하지 않았나 싶다. Ridge, Lasso, 전진선택, 후진제거 모두 결국 선형회귀를 통해 진행한 것인데 이 과정에서 다중공선성을 남겨놓고 진행했기 때문이다.
        4. SGI와 매출액증가율은 결국 같은 변수이기 때문에 중복된 변수였다.
        5. 결론은 선형회귀를 위한 변수 선정을 위해 이상치처리(공격적인 이상치 처리), 스케일링(Standard 또는 Minmax)을 진행하고 선형회귀를 위한 가정을 충족시킨 상태로 변수를 선정하기 위한 3가지 방법 진행 실시
